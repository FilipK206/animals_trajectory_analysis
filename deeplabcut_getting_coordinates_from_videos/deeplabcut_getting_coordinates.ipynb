{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kopia notatnika Untitled9.ipynb","provenance":[{"file_id":"1OYKD5dEQKTV-WH9TgKhAq5CaNc2DmNyM","timestamp":1660844633834}],"collapsed_sections":[],"authorship_tag":"ABX9TyPdgf+ksJ6Aq76XPRTAAorS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"m9C3ZTsAnfyW"},"outputs":[],"source":["pip install deeplabcut"]},{"cell_type":"code","source":["import deeplabcut\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path_config = '/content/drive/My Drive/Habituation-Filip-2022-08-22/config.yaml'\n"],"metadata":{"id":"qDhTCXmro5Xi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661626397021,"user_tz":-120,"elapsed":29738,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"beed3a62-9e73-4ce9-cb7d-28e26f2e284f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading DLC 2.2.2...\n","DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["deeplabcut.create_training_dataset(path_config)"],"metadata":{"id":"J7eBVuGnpE5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deeplabcut.train_network(path_config, saveiters=6000, maxiters= 15000)"],"metadata":{"id":"tagYMKjtp1bt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661288251760,"user_tz":-120,"elapsed":1056749,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"f04bb471-31df-4a05-89f8-88a2dd938400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Config:\n","{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n"," 'all_joints_names': ['front_left_leg',\n","                      'front_right_leg',\n","                      'rear_left_leg',\n","                      'rear_right_leg',\n","                      'cerci',\n","                      'head',\n","                      'left_led',\n","                      'right_led'],\n"," 'alpha_r': 0.02,\n"," 'apply_prob': 0.5,\n"," 'batch_size': 1,\n"," 'contrast': {'clahe': True,\n","              'claheratio': 0.1,\n","              'histeq': True,\n","              'histeqratio': 0.1},\n"," 'convolution': {'edge': False,\n","                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n","                 'embossratio': 0.1,\n","                 'sharpen': False,\n","                 'sharpenratio': 0.3},\n"," 'crop_pad': 0,\n"," 'cropratio': 0.4,\n"," 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HabituationAug22/Habituation_Filip95shuffle1.mat',\n"," 'dataset_type': 'default',\n"," 'decay_steps': 30000,\n"," 'deterministic': False,\n"," 'display_iters': 1000,\n"," 'fg_fraction': 0.25,\n"," 'global_scale': 0.8,\n"," 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n"," 'intermediate_supervision': False,\n"," 'intermediate_supervision_layer': 12,\n"," 'location_refinement': True,\n"," 'locref_huber_loss': True,\n"," 'locref_loss_weight': 0.05,\n"," 'locref_stdev': 7.2801,\n"," 'log_dir': 'log',\n"," 'lr_init': 0.0005,\n"," 'max_input_size': 1500,\n"," 'mean_pixel': [123.68, 116.779, 103.939],\n"," 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HabituationAug22/Documentation_data-Habituation_95shuffle1.pickle',\n"," 'min_input_size': 64,\n"," 'mirror': False,\n"," 'multi_stage': False,\n"," 'multi_step': [[0.005, 10000],\n","                [0.02, 430000],\n","                [0.002, 730000],\n","                [0.001, 1030000]],\n"," 'net_type': 'resnet_50',\n"," 'num_joints': 8,\n"," 'optimizer': 'sgd',\n"," 'pairwise_huber_loss': False,\n"," 'pairwise_predict': False,\n"," 'partaffinityfield_predict': False,\n"," 'pos_dist_thresh': 17,\n"," 'project_path': '/content/drive/My Drive/Habituation-Filip-2022-08-22',\n"," 'regularize': False,\n"," 'rotation': 25,\n"," 'rotratio': 0.4,\n"," 'save_iters': 50000,\n"," 'scale_jitter_lo': 0.5,\n"," 'scale_jitter_up': 1.25,\n"," 'scoremap_dir': 'test',\n"," 'shuffle': True,\n"," 'snapshot_prefix': '/content/drive/My '\n","                    'Drive/Habituation-Filip-2022-08-22/dlc-models/iteration-0/HabituationAug22-trainset95shuffle1/train/snapshot',\n"," 'stride': 8.0,\n"," 'weigh_negatives': False,\n"," 'weigh_only_present_joints': False,\n"," 'weigh_part_predictions': False,\n"," 'weight_decay': 0.0001}\n"]},{"output_type":"stream","name":"stdout","text":["Selecting single-animal trainer\n","Batch Size is 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  warnings.warn('`layer.apply` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:684: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n","  outputs = layer.apply(inputs, training=is_training)\n"]},{"output_type":"stream","name":"stdout","text":["Loading ImageNet-pretrained resnet_50\n","Max_iters overwritten as 15000\n","Save_iters overwritten as 6000\n","Training parameter:\n","{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/content/drive/My Drive/Habituation-Filip-2022-08-22/dlc-models/iteration-0/HabituationAug22-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['front_left_leg', 'front_right_leg', 'rear_left_leg', 'rear_right_leg', 'cerci', 'head', 'left_led', 'right_led'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HabituationAug22/Habituation_Filip95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HabituationAug22/Documentation_data-Habituation_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 8, 'pos_dist_thresh': 17, 'project_path': '/content/drive/My Drive/Habituation-Filip-2022-08-22', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n","Starting training....\n"]},{"output_type":"stream","name":"stderr","text":["iteration: 1000 loss: 0.0294 lr: 0.005\n","iteration: 2000 loss: 0.0194 lr: 0.005\n","iteration: 3000 loss: 0.0170 lr: 0.005\n","iteration: 4000 loss: 0.0151 lr: 0.005\n","iteration: 5000 loss: 0.0137 lr: 0.005\n","iteration: 6000 loss: 0.0130 lr: 0.005\n","iteration: 7000 loss: 0.0122 lr: 0.005\n","iteration: 8000 loss: 0.0118 lr: 0.005\n","iteration: 9000 loss: 0.0112 lr: 0.005\n","iteration: 10000 loss: 0.0108 lr: 0.005\n","iteration: 11000 loss: 0.0126 lr: 0.02\n","iteration: 12000 loss: 0.0121 lr: 0.02\n","iteration: 13000 loss: 0.0108 lr: 0.02\n","iteration: 14000 loss: 0.0096 lr: 0.02\n","iteration: 15000 loss: 0.0087 lr: 0.02\n"]},{"output_type":"stream","name":"stdout","text":["The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"]},{"output_type":"stream","name":"stderr","text":["Exception in thread Thread-13:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue\n","    sess.run(enqueue_op, feed_dict=food)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 968, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\", line 1115, in _run\n","    raise RuntimeError('Attempted to use a closed Session.')\n","RuntimeError: Attempted to use a closed Session.\n","\n"]}]},{"cell_type":"code","source":["deeplabcut.evaluate_network(path_config)"],"metadata":{"id":"ul2kiRMDrymE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deeplabcut.analyze_videos(path_config,  ['/content/drive/My Drive/Habituation-Filip-2022-08-22/videos'])"],"metadata":{"id":"Mskvz2hqsCs8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deeplabcut.analyze_videos(path_config,  ['/content/drive/My Drive/Habituation-Filip-2022-08-22/videos/'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QhngZoRxaABT","executionInfo":{"status":"ok","timestamp":1661292874556,"user_tz":-120,"elapsed":3024238,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"ad7ed6dd-af3c-4fa2-b4cc-8e124da8a9f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Config:\n","{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n"," 'all_joints_names': ['front_left_leg',\n","                      'front_right_leg',\n","                      'rear_left_leg',\n","                      'rear_right_leg',\n","                      'cerci',\n","                      'head',\n","                      'left_led',\n","                      'right_led'],\n"," 'batch_size': 1,\n"," 'crop_pad': 0,\n"," 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_HabituationAug22/Habituation_Filip95shuffle1.mat',\n"," 'dataset_type': 'imgaug',\n"," 'deterministic': False,\n"," 'fg_fraction': 0.25,\n"," 'global_scale': 0.8,\n"," 'init_weights': '/usr/local/lib/python3.7/dist-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n"," 'intermediate_supervision': False,\n"," 'intermediate_supervision_layer': 12,\n"," 'location_refinement': True,\n"," 'locref_huber_loss': True,\n"," 'locref_loss_weight': 1.0,\n"," 'locref_stdev': 7.2801,\n"," 'log_dir': 'log',\n"," 'mean_pixel': [123.68, 116.779, 103.939],\n"," 'mirror': False,\n"," 'net_type': 'resnet_50',\n"," 'num_joints': 8,\n"," 'optimizer': 'sgd',\n"," 'pairwise_huber_loss': True,\n"," 'pairwise_predict': False,\n"," 'partaffinityfield_predict': False,\n"," 'regularize': False,\n"," 'scoremap_dir': 'test',\n"," 'shuffle': True,\n"," 'snapshot_prefix': '/content/drive/My '\n","                    'Drive/Habituation-Filip-2022-08-22/dlc-models/iteration-0/HabituationAug22-trainset95shuffle1/test/snapshot',\n"," 'stride': 8.0,\n"," 'weigh_negatives': False,\n"," 'weigh_only_present_joints': False,\n"," 'weigh_part_predictions': False,\n"," 'weight_decay': 0.0001}\n"]},{"output_type":"stream","name":"stdout","text":["Using snapshot-15000 for model /content/drive/My Drive/Habituation-Filip-2022-08-22/dlc-models/iteration-0/HabituationAug22-trainset95shuffle1\n","Analyzing all the videos in the directory...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_150135_066.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_150135_066.avi\n","Duration of video [s]:  599.27 , recorded with  30.0 fps!\n","Overall # of frames:  17978  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17978 [03:54<00:01, 76.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_153342_448.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_153342_448.avi\n","Duration of video [s]:  599.3 , recorded with  30.0 fps!\n","Overall # of frames:  17979  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17979 [03:51<00:01, 77.44it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_151836_476.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_151836_476.avi\n","Duration of video [s]:  599.2 , recorded with  30.0 fps!\n","Overall # of frames:  17976  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17976 [03:55<00:00, 76.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_160318_546.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_160318_546.avi\n","Duration of video [s]:  599.3 , recorded with  30.0 fps!\n","Overall # of frames:  17979  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17979 [03:47<00:01, 78.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_141829_291.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_141829_291.avi\n","Duration of video [s]:  599.47 , recorded with  30.0 fps!\n","Overall # of frames:  17984  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17984 [03:46<00:01, 78.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_161928_065.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_161928_065.avi\n","Duration of video [s]:  599.3 , recorded with  30.0 fps!\n","Overall # of frames:  17979  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17979 [03:47<00:01, 78.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_144546_209.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_144546_209.avi\n","Duration of video [s]:  599.53 , recorded with  30.0 fps!\n","Overall # of frames:  17986  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17986 [03:47<00:01, 78.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_162814_631.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_162814_631.avi\n","Duration of video [s]:  599.23 , recorded with  30.0 fps!\n","Overall # of frames:  17977  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17977 [03:49<00:00, 78.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_160840_013.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_160840_013.avi\n","Duration of video [s]:  599.13 , recorded with  30.0 fps!\n","Overall # of frames:  17974  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17974 [03:48<00:00, 78.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_150436_249.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_150436_249.avi\n","Duration of video [s]:  599.33 , recorded with  30.0 fps!\n","Overall # of frames:  17980  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17980 [03:53<00:01, 76.58it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi\n","Duration of video [s]:  599.13 , recorded with  30.0 fps!\n","Overall # of frames:  17974  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17974 [03:49<00:00, 78.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_152541_562.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_152541_562.avi\n","Duration of video [s]:  599.2 , recorded with  30.0 fps!\n","Overall # of frames:  17976  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17976 [03:53<00:00, 76.56it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_160837_734.avi\n","Starting to analyze %  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_154758_285.avi\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_154758_285.avi\n","Duration of video [s]:  598.67 , recorded with  30.0 fps!\n","Overall # of frames:  17960  found with (before cropping) frame dimensions:  640 480\n","Starting to extract posture\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 17900/17960 [03:49<00:00, 78.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saving results in /content/drive/My Drive/Habituation-Filip-2022-08-22/videos...\n","The videos are analyzed. Now your research can truly start! \n"," You can create labeled videos with 'create_labeled_video'\n","If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"]},{"output_type":"execute_result","data":{"text/plain":["'DLC_resnet50_HabituationAug22shuffle1_15000'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["deeplabcut.filterpredictions(path_config, ['/content/drive/My Drive/Habituation-Filip-2022-08-22/videos'])"],"metadata":{"id":"DZIRQn1xLloy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661441585350,"user_tz":-120,"elapsed":35696,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"5d39e6b4-8e64-41f3-eb39-83a40b57d80d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Analyzing all the videos in the directory...\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_141829_291.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_152541_562.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_161928_065.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_150436_249.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_144546_209.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_162814_631.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_160318_546.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_150135_066.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_151836_476.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_160837_734.avi\n","Data from 2022-08-03_160837_734 were already filtered. Skipping...\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_153342_448.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_160840_013.avi\n","Saving filtered csv poses!\n","Filtering with median model /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_154758_285.avi\n","Saving filtered csv poses!\n"]}]},{"cell_type":"code","source":["deeplabcut.create_labeled_video(path_config, ['/content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi'], videotype=\"avi\", filtered=True) #do poprawy ścieżka pliku"],"metadata":{"id":"UtfjB5M7n1g0","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1661626481335,"user_tz":-120,"elapsed":62791,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"373b60b6-2f83-46ff-e227-b319c3499c06"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting to process video: /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi\n","Loading /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi and data.\n","Duration of video [s]: 599.13, recorded with 30.0 fps!\n","Overall # of frames: 17974 with cropped frame dimensions: 640 480\n","Generating frames and creating video.\n"]},{"output_type":"stream","name":"stderr","text":[" 98%|█████████▊| 17637/17974 [00:53<00:01, 327.23it/s]\n"]},{"output_type":"error","ename":"AxisError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)","\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\", line 736, in proc_video\n    fps=outputframerate,\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\", line 813, in _create_labeled_video\n    color_by,\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\", line 182, in CreateVideo\n    clip.save_frame(image)\n  File \"/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/video_processor.py\", line 149, in save_frame\n    self.svid.write(np.flip(frame, 2))\n  File \"<__array_function__ internals>\", line 6, in flip\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py\", line 236, in flip\n    axis = _nx.normalize_axis_tuple(axis, m.ndim)\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\", line 1385, in normalize_axis_tuple\n    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\", line 1385, in <listcomp>\n    axis = tuple([normalize_axis_index(ax, ndim, argname) for ax in axis])\nnumpy.AxisError: axis 2 is out of bounds for array of dimension 0\n\"\"\"","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-659be657a904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_labeled_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'/content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideotype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"avi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#do poprawy ścieżka pliku\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\u001b[0m in \u001b[0;36mcreate_labeled_video\u001b[0;34m(config, videos, videotype, shuffle, trainingsetindex, filtered, fastmode, save_frames, keypoints_only, Frames2plot, displayedbodyparts, displayedindividuals, codec, outputframerate, destfolder, draw_skeleton, trailpoints, displaycropped, color_by, modelprefix, track_method)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVideos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVideos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\u001b[0m in \u001b[0;36mproc_video\u001b[0;34m()\u001b[0m\n\u001b[1;32m    734\u001b[0m                     \u001b[0mskeleton_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskeleton_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                     \u001b[0mtrailpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrailpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                     \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputframerate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m                 )\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\u001b[0m in \u001b[0;36m_create_labeled_video\u001b[0;34m()\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskeleton_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mdisplay_cropped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mcolor_by\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m     )\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/make_labeled_video.py\u001b[0m in \u001b[0;36mCreateVideo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeplabcut/utils/video_processor.py\u001b[0m in \u001b[0;36msave_frame\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mflip\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m()\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 0"]}]},{"cell_type":"code","source":["import matplotlib\n","deeplabcut.filterpredictions(config_path, ['/content/drive/My Drive/Habituation-Filip-2022-08-22/videos'], comparisonbodyparts='all', filtertype='arima', p_bound=0.01, ARdegree=3, MAdegree=1, alpha=0.01)"],"metadata":{"id":"7AkUDijHKp4M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661292905149,"user_tz":-120,"elapsed":30308,"user":{"displayName":"Filip Kozal","userId":"01100954392688126014"}},"outputId":"2f37f2e0-42cb-4e83-e701-c9e13b6ab766"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Analyzing all the videos in the directory...\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_160837_734.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_160318_546.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_144546_209.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_153342_448.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_160840_013.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_152541_562.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_161928_065.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_151836_476.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_162814_631.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_141829_291.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-03_155340_951.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_150436_249.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-04_154758_285.avi and data.\n","Loading  /content/drive/My Drive/Habituation-Filip-2022-08-22/videos/2022-08-05_150135_066.avi and data.\n","Plots created! Please check the directory \"plot-poses\" within the video directory\n"]}]}]}